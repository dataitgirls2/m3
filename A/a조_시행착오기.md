### 크롤링지옥 (이지윤)

1. 1차 크롤러 
- 셀레늄과 beautifulSoup를 이용해 네이버 블로그(m.blog.naver url을 포함하는 주소를 가진)의 제목/시간/포스팅 본문을 가져와 엑셀에 저장했다. 
- 해결 : 포스팅의 본문 내용을 저장하지 않고 제목만 넣었다. 
- 문제 : 샘플로 몇 개의 식당만 크롤링 했을때에는 문제가 없었으나 50개가 넘는 식당에 대한 블로그 포스팅의 제목, 시간, 본문을 모두 엑셀에 넣으려니 느리고 용량이 커서 에러가 나는 문제가 있었다. 

2. 2차 크롤러
- 문제 : 제목만 넣는다고 하지만, 모든 블로그 포스팅에 진입하여 제목을 가져와 속도가 느렸다. 그리고 네이버 말고 티스토리 등 다른 블로그들을 가져오지 못했고, 네이버 블로그 중에서도 blog.me url이 있다는 것을 알지 못했다. 
- 해결 : 일단은 크롤링 다시 하기가 겁나서 있는 데이터로 분석을 해보기로 했다. 



### 통계분석 : 분석이 안된다... (장예빈)

1. 짝테스트
   - 문제: 마이너스 값이 있다, 정규분포를 따르지 않는다
   - 해결: 더 큰 데이터로 해결
2. 회귀분석
   - 문제 : 2018년걸로 분산분석이 통계적으로 유의하지 않았다
   - 해결 : 2017년걸 합쳤는데, 유의수준은 괜찮았는데 r스퀘어 값이 낮았다. 



### 지도 찍기 (최지영)

1. 중간 결과물로 빠르게 피드백을 받아보자.
- 크롤링을 위해 팀원들과 작업한 raw data를 가지고 구글 맛집 지도 완성
- 상위 15개의 맛집 관련 페이스북 페이지에 지도 제보
- 지도 뷰수 3만, 공유 1.5천회 달성 (18-08-27 기준) 

### 크롤러 다시 만들기 (이지윤)

- 문제 : 
      - 빠진 데이터가 너무 많았다. 
      - 네이버 블로그도 me.blog url을 고려하지 못해서 모두 담지 못하고 있었다. (naver.blog)
      - 네이버 외에도 티스토리, 다음 등 의외로 다른 블로그에 맛집 포스팅의 갯수가 많았다. 
      - 네이버 블로그에도 에디터가 있어 에디터에 따라 제목이나 날짜가 다른 css selector로 지정되어 있어 데이터에 null값이 많았다. 
      - 한달 만으로는 추이를 보기 힘들었
- 해결 : 
   - 데이터 크롤링 기간을 방송 전/후3개월로 늘렸다. 
   - 블로그 포스팅을 클릭해 들어가서 내용 등을 가져오지 않고 검색한 페이지에서 날짜와 제목만 가져오게 수정
   - 포스팅을 클릭해 들어가지 않으니 크롤링 시간이 1/10로 줄었다. 



